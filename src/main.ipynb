{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8edc722f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def load_datasets(base_path='e:\\\\SEMESTER 5\\\\DEEP LEARNING\\\\FINAL\\\\neurips-open-polymer-prediction-2025'):\n",
    "    \"\"\"\n",
    "    Load all datasets from the project directory.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    base_path : str\n",
    "        Base path to the project directory\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary containing all loaded datasets\n",
    "    \"\"\"\n",
    "    datasets = {}\n",
    "    \n",
    "    # Load main train dataset\n",
    "    train_path = os.path.join(base_path, 'train.csv')\n",
    "    datasets['train'] = pd.read_csv(train_path)\n",
    "    # Load main test dataset\n",
    "    test_path = os.path.join(base_path, 'test.csv')\n",
    "    datasets['test'] = pd.read_csv(test_path)\n",
    "    \n",
    "    # Load supplementary datasets\n",
    "    supplement_path = os.path.join(base_path, 'train_supplement')\n",
    "    for i in range(1, 5):\n",
    "        dataset_path = os.path.join(supplement_path, f'dataset{i}.csv')\n",
    "        datasets[f'dataset{i}'] = pd.read_csv(dataset_path)\n",
    "    \n",
    "    return datasets\n",
    "\n",
    "\n",
    "data = load_datasets()\n",
    "test_df = data['test']\n",
    "train_df = data['train']\n",
    "dataset1_df = data['dataset1']\n",
    "dataset2_df = data['dataset2']\n",
    "dataset3_df = data['dataset3']\n",
    "dataset4_df = data['dataset4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5072dba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem \n",
    "from rdkit.Chem import AllChem \n",
    "from rdkit.Chem.rdmolops import RemoveHs\n",
    "\n",
    "def safe_mol_from_smiles(smiles):\n",
    "    if pd.isna(smiles) or not isinstance(smiles, str) or smiles.strip() == '':\n",
    "        return None\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        return mol\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "def largest_fragment(mol):\n",
    "    frags = Chem.GetMolFrags(mol, asMols=True)\n",
    "    if len(frags) == 1:\n",
    "        return mol\n",
    "    largest = max(frags, key=lambda m: m.GetNumAtoms())\n",
    "    return largest\n",
    "\n",
    "def neutralize_molecule(mol):\n",
    "    try:\n",
    "        # RDKit built-in neutralization\n",
    "        uncharger = Chem.rdMolStandardize.Uncharger()\n",
    "        mol = uncharger.uncharge(mol)\n",
    "        return mol\n",
    "    except:\n",
    "        return mol\n",
    "    \n",
    "def canonicalize(mol):\n",
    "    try:\n",
    "        return Chem.MolToSmiles(mol, canonical=True)\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "    \n",
    "def sanitize_smiles_pipeline(smiles):\n",
    "    # Step 1: Safe Mol\n",
    "    mol = safe_mol_from_smiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "\n",
    "    # Step 2: Remove salts\n",
    "    mol = largest_fragment(mol)\n",
    "\n",
    "    # Step 3: Neutralize\n",
    "    mol = neutralize_molecule(mol)\n",
    "\n",
    "    # Step 4: Re-sanitize\n",
    "    try:\n",
    "        Chem.SanitizeMol(mol)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "    # Step 5: Canonicalize\n",
    "    return canonicalize(mol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81495d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====================================\n",
      "üîé QC for test_df\n",
      "=====================================\n",
      "Total entries:                  3\n",
      "Valid sanitized molecules:      3\n",
      "Invalid molecules:              0\n",
      "Raw unique SMILES:              3\n",
      "Canonical unique SMILES:        3\n",
      "Duplicates lost after cleaning: 0\n",
      "-------------------------------------\n",
      "‚úÖ No invalid molecules.\n",
      "\n",
      "=====================================\n",
      "üîé QC for train_df\n",
      "=====================================\n",
      "Total entries:                  7973\n",
      "Valid sanitized molecules:      7973\n",
      "Invalid molecules:              0\n",
      "Raw unique SMILES:              7973\n",
      "Canonical unique SMILES:        7973\n",
      "Duplicates lost after cleaning: 0\n",
      "-------------------------------------\n",
      "‚úÖ No invalid molecules.\n",
      "\n",
      "=====================================\n",
      "üîé QC for dataset1_df\n",
      "=====================================\n",
      "Total entries:                  874\n",
      "Valid sanitized molecules:      874\n",
      "Invalid molecules:              0\n",
      "Raw unique SMILES:              867\n",
      "Canonical unique SMILES:        866\n",
      "Duplicates lost after cleaning: 1\n",
      "-------------------------------------\n",
      "‚úÖ No invalid molecules.\n",
      "\n",
      "=====================================\n",
      "üîé QC for dataset2_df\n",
      "=====================================\n",
      "Total entries:                  7208\n",
      "Valid sanitized molecules:      7208\n",
      "Invalid molecules:              0\n",
      "Raw unique SMILES:              7174\n",
      "Canonical unique SMILES:        7174\n",
      "Duplicates lost after cleaning: 0\n",
      "-------------------------------------\n",
      "‚úÖ No invalid molecules.\n",
      "\n",
      "=====================================\n",
      "üîé QC for dataset3_df\n",
      "=====================================\n",
      "Total entries:                  46\n",
      "Valid sanitized molecules:      46\n",
      "Invalid molecules:              0\n",
      "Raw unique SMILES:              46\n",
      "Canonical unique SMILES:        46\n",
      "Duplicates lost after cleaning: 0\n",
      "-------------------------------------\n",
      "‚úÖ No invalid molecules.\n",
      "\n",
      "=====================================\n",
      "üîé QC for dataset4_df\n",
      "=====================================\n",
      "Total entries:                  862\n",
      "Valid sanitized molecules:      862\n",
      "Invalid molecules:              0\n",
      "Raw unique SMILES:              862\n",
      "Canonical unique SMILES:        862\n",
      "Duplicates lost after cleaning: 0\n",
      "-------------------------------------\n",
      "‚úÖ No invalid molecules.\n"
     ]
    }
   ],
   "source": [
    "# Replace your validate_smiles_entries call with this:\n",
    "\n",
    "def validate_smiles_entries_dict(dfs_dict, smiles_column=\"SMILES\"):\n",
    "    \"\"\"\n",
    "    SMILES validation using explicit dictionary keys.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    for df_name, df in dfs_dict.items():\n",
    "        df_copy = df.copy()\n",
    "\n",
    "        canonical_list = []\n",
    "        errors = []\n",
    "\n",
    "        for s in df_copy[smiles_column]:\n",
    "            try:\n",
    "                mol = Chem.MolFromSmiles(s, sanitize=True)\n",
    "                if mol is None:\n",
    "                    canonical_list.append(None)\n",
    "                    errors.append({\"SMILES\": s, \"error\": \"MolFromSmiles returned None\"})\n",
    "                else:\n",
    "                    canon = Chem.MolToSmiles(mol, canonical=True)\n",
    "                    canonical_list.append(canon)\n",
    "                    errors.append(None)\n",
    "            except Exception as e:\n",
    "                canonical_list.append(None)\n",
    "                errors.append({\"SMILES\": s, \"error\": str(e)})\n",
    "\n",
    "        df_copy[\"canonical_SMILES\"] = canonical_list\n",
    "        df_copy[\"sanitization_error\"] = errors\n",
    "\n",
    "        # Summary QC\n",
    "        total = len(df_copy)\n",
    "        valid = df_copy[\"canonical_SMILES\"].notna().sum()\n",
    "        invalid = total - valid\n",
    "        unique_raw = df_copy[smiles_column].nunique()\n",
    "        unique_canon = df_copy[\"canonical_SMILES\"].nunique()\n",
    "\n",
    "        print(\"\\n=====================================\")\n",
    "        print(f\"üîé QC for {df_name}\")\n",
    "        print(\"=====================================\")\n",
    "        print(f\"Total entries:                  {total}\")\n",
    "        print(f\"Valid sanitized molecules:      {valid}\")\n",
    "        print(f\"Invalid molecules:              {invalid}\")\n",
    "        print(f\"Raw unique SMILES:              {unique_raw}\")\n",
    "        print(f\"Canonical unique SMILES:        {unique_canon}\")\n",
    "        print(f\"Duplicates lost after cleaning: {unique_raw - unique_canon}\")\n",
    "        print(\"-------------------------------------\")\n",
    "\n",
    "        invalid_df = df_copy[df_copy[\"canonical_SMILES\"].isna()]\n",
    "        if len(invalid_df) > 0:\n",
    "            print(\"‚ùå Invalid molecules found:\")\n",
    "            print(invalid_df[[smiles_column, \"sanitization_error\"]].head())\n",
    "        else:\n",
    "            print(\"‚úÖ No invalid molecules.\")\n",
    "\n",
    "        results[df_name] = {\n",
    "            \"clean_df\": df_copy[df_copy[\"canonical_SMILES\"].notna()].copy(),\n",
    "            \"invalid_df\": invalid_df.copy(),\n",
    "            \"full_df\": df_copy,\n",
    "        }\n",
    "\n",
    "    return results\n",
    "\n",
    "# Use explicit dictionary with names\n",
    "checklist = {\n",
    "    'test_df': test_df,\n",
    "    'train_df': train_df,\n",
    "    'dataset1_df': dataset1_df,\n",
    "    'dataset2_df': dataset2_df,\n",
    "    'dataset3_df': dataset3_df,\n",
    "    'dataset4_df': dataset4_df\n",
    "}\n",
    "\n",
    "qc_results = validate_smiles_entries_dict(checklist)\n",
    "\n",
    "# Now extract cleaned DataFrames\n",
    "train_df = qc_results['train_df']['clean_df']\n",
    "dataset1_df = qc_results['dataset1_df']['clean_df']\n",
    "dataset2_df = qc_results['dataset2_df']['clean_df']\n",
    "dataset3_df = qc_results['dataset3_df']['clean_df']\n",
    "dataset4_df = qc_results['dataset4_df']['clean_df']\n",
    "test_df = qc_results['test_df']['clean_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5aeaddec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Prepare] Rows before=7973, after deduplicate=7973\n",
      "[Prepare] Rows before=874, after deduplicate=866\n",
      "[Prepare] Rows before=46, after deduplicate=46\n",
      "[Prepare] Rows before=862, after deduplicate=862\n",
      "\n",
      "===== BEFORE MERGE STATS =====\n",
      "Dataset 1: rows=7973, unique keys=7973\n",
      "Dataset 2: rows=866, unique keys=866\n",
      "Dataset 3: rows=46, unique keys=46\n",
      "Dataset 4: rows=862, unique keys=862\n",
      "\n",
      "===== AFTER MERGE STATS =====\n",
      "Merged rows=8972\n",
      "Merged unique keys=8972\n",
      "[Prepare] Rows before=8972, after deduplicate=8972\n",
      "[Prepare] Rows before=7208, after deduplicate=7174\n",
      "\n",
      "===== BEFORE MERGE STATS =====\n",
      "Dataset 1: rows=8972, unique keys=8972\n",
      "Dataset 2: rows=7174, unique keys=7174\n",
      "\n",
      "===== AFTER MERGE STATS =====\n",
      "Merged rows=10343\n",
      "Merged unique keys=10343\n",
      "\n",
      "===== AUGMENTATION DIAGNOSTICS =====\n",
      "New molecules added: 1371\n",
      "Molecules missing (should be 0): 0\n",
      "Example added rows:\n",
      "   id  Tg  FFV  Tc  Density  Rg  \\\n",
      "0 NaN NaN  NaN NaN      NaN NaN   \n",
      "1 NaN NaN  NaN NaN      NaN NaN   \n",
      "2 NaN NaN  NaN NaN      NaN NaN   \n",
      "3 NaN NaN  NaN NaN      NaN NaN   \n",
      "4 NaN NaN  NaN NaN      NaN NaN   \n",
      "\n",
      "                                    canonical_SMILES sanitization_error  \\\n",
      "0              */C(=C(/*)c1ccc(C(C)(C)C)cc1)c1ccccc1                NaN   \n",
      "1                  */C(=C(/*)c1ccc(CCCC)cc1)c1ccccc1                NaN   \n",
      "2             */C(=C(/*)c1ccc(Oc2ccccc2)cc1)c1ccccc1                NaN   \n",
      "3  */C(=C(/*)c1ccc([Si](C(C)C)(C(C)C)C(C)C)cc1)c1...                NaN   \n",
      "4           */C(=C(/*)c1ccc([Si](C)(C)C)cc1)c1ccccc1                NaN   \n",
      "\n",
      "   TC_mean  \n",
      "0      NaN  \n",
      "1      NaN  \n",
      "2      NaN  \n",
      "3      NaN  \n",
      "4      NaN  \n"
     ]
    }
   ],
   "source": [
    "dataset_merge = [train_df, dataset1_df, dataset3_df, dataset4_df]\n",
    "dataset_cluster = [dataset2_df]\n",
    "\n",
    "def prepare_for_merge(df, key=\"canonical_SMILES\"):\n",
    "    \"\"\"\n",
    "    Remove duplicate SMILES columns and preserve only the key for merging.\n",
    "    Keeps track of original row count and unique keys.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Drop raw SMILES if canonical is used for merge\n",
    "    if \"SMILES\" in df.columns and key != \"SMILES\":\n",
    "        df = df.drop(columns=[\"SMILES\"])\n",
    "\n",
    "    # Drop duplicate key rows\n",
    "    before = len(df)\n",
    "    df = df.drop_duplicates(subset=[key])\n",
    "    after = len(df)\n",
    "\n",
    "    print(f\"[Prepare] Rows before={before}, after deduplicate={after}\")\n",
    "    return df\n",
    "from functools import reduce\n",
    "\n",
    "def robust_merge(datasets, key=\"canonical_SMILES\"):\n",
    "    \"\"\"\n",
    "    Safely merges multiple datasets on canonical SMILES.\n",
    "    Logs before/after information for traceability.\n",
    "    \"\"\"\n",
    "    # Prepare datasets\n",
    "    cleaned = [prepare_for_merge(df, key=key) for df in datasets]\n",
    "\n",
    "    # Log BEFORE merge stats\n",
    "    print(\"\\n===== BEFORE MERGE STATS =====\")\n",
    "    for i, df in enumerate(cleaned):\n",
    "        print(f\"Dataset {i+1}: rows={len(df)}, unique keys={df[key].nunique()}\")\n",
    "\n",
    "    # Reduce merge\n",
    "    merged = reduce(\n",
    "        lambda left, right: left.merge(\n",
    "            right, on=key, how=\"outer\", suffixes=(\"\", \"_dup\")\n",
    "        ),\n",
    "        cleaned\n",
    "    )\n",
    "\n",
    "    # Clean leftover duplicate columns (_dup)\n",
    "    dup_cols = [c for c in merged.columns if c.endswith(\"_dup\")]\n",
    "    if dup_cols:\n",
    "        merged = merged.drop(columns=dup_cols)\n",
    "\n",
    "    # Log AFTER merge stats\n",
    "    print(\"\\n===== AFTER MERGE STATS =====\")\n",
    "    print(f\"Merged rows={len(merged)}\")\n",
    "    print(f\"Merged unique keys={merged[key].nunique()}\")\n",
    "\n",
    "    return merged\n",
    "\n",
    "\n",
    "def compare_augmentation(base_df, augmented_df, key=\"canonical_SMILES\"):\n",
    "    \"\"\"\n",
    "    Show which molecules the external datasets added.\n",
    "    \"\"\"\n",
    "    base_keys = set(base_df[key])\n",
    "    aug_keys = set(augmented_df[key])\n",
    "\n",
    "    added = aug_keys - base_keys\n",
    "    lost  = base_keys - aug_keys  # should be empty unless outer merge\n",
    "\n",
    "    print(\"\\n===== AUGMENTATION DIAGNOSTICS =====\")\n",
    "    print(f\"New molecules added: {len(added)}\")\n",
    "    print(f\"Molecules missing (should be 0): {len(lost)}\")\n",
    "\n",
    "    added_df = augmented_df[augmented_df[key].isin(added)]\n",
    "    print(\"Example added rows:\")\n",
    "    print(added_df.head())\n",
    "\n",
    "    return added_df\n",
    "\n",
    "df_internal = robust_merge(dataset_merge, key=\"canonical_SMILES\")\n",
    "df_augmented = robust_merge([df_internal] + dataset_cluster)\n",
    "\n",
    "augment_inspection = compare_augmentation(df_internal, df_augmented)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "708d8648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Tg",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "FFV",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Tc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Density",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Rg",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "canonical_SMILES",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sanitization_error",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "TC_mean",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "84d06b41-b006-4915-b413-6ee02752546a",
       "rows": [
        [
         "0",
         null,
         null,
         null,
         null,
         null,
         null,
         "*/C(=C(/*)c1ccc(C(C)(C)C)cc1)c1ccccc1",
         null,
         null
        ],
        [
         "1",
         null,
         null,
         null,
         null,
         null,
         null,
         "*/C(=C(/*)c1ccc(CCCC)cc1)c1ccccc1",
         null,
         null
        ],
        [
         "2",
         null,
         null,
         null,
         null,
         null,
         null,
         "*/C(=C(/*)c1ccc(Oc2ccccc2)cc1)c1ccccc1",
         null,
         null
        ],
        [
         "3",
         null,
         null,
         null,
         null,
         null,
         null,
         "*/C(=C(/*)c1ccc([Si](C(C)C)(C(C)C)C(C)C)cc1)c1ccccc1",
         null,
         null
        ],
        [
         "4",
         null,
         null,
         null,
         null,
         null,
         null,
         "*/C(=C(/*)c1ccc([Si](C)(C)C)cc1)c1ccccc1",
         null,
         null
        ],
        [
         "5",
         null,
         null,
         null,
         null,
         null,
         null,
         "*/C(=C(/*)c1ccc[c]([Ge]([CH3])([CH3])[CH3])c1)c1ccccc1",
         null,
         null
        ],
        [
         "6",
         null,
         null,
         null,
         null,
         null,
         null,
         "*/C(=C(/*)c1cccc([Si](C)(C)C)c1)c1ccccc1",
         null,
         null
        ],
        [
         "7",
         "218059466.0",
         "206.5698859",
         null,
         null,
         null,
         null,
         "*/C(=C(/*)c1ccccc1)c1ccccc1",
         null,
         null
        ],
        [
         "8",
         null,
         null,
         null,
         null,
         null,
         null,
         "*/C(=C(/c1ccc(*)cc1)c1ccc(Oc2ccccc2)cc1)c1ccc(Oc2ccccc2)cc1",
         null,
         null
        ],
        [
         "9",
         null,
         null,
         null,
         null,
         null,
         null,
         "*/C(=C(\\C#N)c1ccc(C(=O)OC2CCN(*)CC2)cc1)c1ccc(OC)cc1",
         null,
         null
        ],
        [
         "10",
         null,
         null,
         null,
         null,
         null,
         null,
         "*/C(=C(\\[2H])C([2H])([2H])C(*)([2H])[2H])C([2H])([2H])[2H]",
         null,
         null
        ],
        [
         "11",
         null,
         null,
         null,
         null,
         null,
         null,
         "*/C(=C(\\c1ccccc1)c1ccc(*)cc1)c1ccccc1",
         null,
         "0.338"
        ],
        [
         "12",
         null,
         null,
         null,
         null,
         null,
         null,
         "*/C(=C/c1cc(OC)c(/C=C(/c2ccc(*)cc2)c2ccc(C(F)(F)F)cc2)cc1OC)c1ccc(C(F)(F)F)cc1",
         null,
         null
        ],
        [
         "13",
         null,
         null,
         null,
         null,
         null,
         null,
         "*/C(=C/c1cc(OC)c(/C=C(/c2ccc(*)cc2)c2ccc(F)cc2)cc1OC)c1ccc(F)cc1",
         null,
         null
        ],
        [
         "14",
         null,
         null,
         null,
         null,
         null,
         null,
         "*/C(=C/c1cc(OC)c(/C=C(/c2ccc(*)cc2)c2ccc(OC)cc2)cc1OC)c1ccc(OC)cc1",
         null,
         null
        ],
        [
         "15",
         null,
         null,
         null,
         null,
         null,
         null,
         "*/C(=C/c1cc(OC)c(/C=C(\\c2ccc(F)cc2)c2ccc(-c3ccc(*)cc3)cc2)cc1OC)c1ccc(F)cc1",
         null,
         null
        ],
        [
         "16",
         null,
         null,
         null,
         null,
         null,
         null,
         "*/C(=C/c1cc(OC)c(/C=C(\\c2ccc(F)cc2)c2ccc3cc(*)ccc3c2)cc1OC)c1ccc(F)cc1",
         null,
         null
        ],
        [
         "17",
         null,
         null,
         null,
         null,
         null,
         null,
         "*/C(=C/c1cc(OC)c(/C=C(\\c2ccccc2)c2ccc(-c3ccc(*)cc3)cc2)cc1OC)c1ccccc1",
         null,
         null
        ],
        [
         "18",
         null,
         null,
         null,
         null,
         null,
         null,
         "*/C(=C/c1cc(OC)c(/C=C(\\c2ccccc2)c2ccc3cc(*)ccc3c2)cc1OC)c1ccccc1",
         null,
         null
        ],
        [
         "19",
         null,
         null,
         null,
         null,
         null,
         null,
         "*/C(=C/c1cc(OCCCCCCCC)c(/C=C(\\c2ccccc2)c2ccc3c(c2)Sc2ccc(*)cc2S3)cc1OCCCCCCCC)c1ccccc1",
         null,
         null
        ],
        [
         "20",
         null,
         null,
         null,
         null,
         null,
         null,
         "*/C(=C/c1ccc(/C=C(\\c2ccccc2)c2ccc(-c3ccc(*)cc3)cc2)cc1)c1ccccc1",
         null,
         null
        ],
        [
         "21",
         null,
         null,
         null,
         null,
         null,
         null,
         "*/C(=N\\c1ccccc1)c1ccc(-c2ccc(*)cc2)cc1",
         null,
         null
        ],
        [
         "22",
         null,
         null,
         null,
         null,
         null,
         null,
         "*/C(C#N)=C(\\C#N)N1C(=O)c2ccc(C(=O)c3ccc(-c4ccc5c(c4)C(=O)N(*)C5=O)cc3)cc2C1=O",
         null,
         null
        ],
        [
         "23",
         null,
         null,
         null,
         null,
         null,
         null,
         "*/C(C#N)=C(\\C#N)n1c(=O)c2cc3c(=O)n(*)c(=O)c3cc2c1=O",
         null,
         null
        ],
        [
         "24",
         null,
         null,
         null,
         null,
         null,
         null,
         "*/C(C#N)=C/c1cc(/C=C(\\C#N)c2ccc3c(c2)C(CCCCCCCC)(CCCCCCCC)c2cc(*)ccc2-3)cc(N(c2ccccc2)c2ccccc2)c1",
         null,
         null
        ],
        [
         "25",
         null,
         null,
         null,
         null,
         null,
         null,
         "*/C(C#N)=C/c1cc(OCC(CC)CCCC)c(/C=C(\\C#N)c2ccc3c4ccc(*)cc4n(CC(CC)CCCC)c3c2)cc1OCC(CC)CCCC",
         null,
         null
        ],
        [
         "26",
         null,
         null,
         null,
         null,
         null,
         null,
         "*/C(C#N)=C/c1cc(OCCCCCCCC)c(/C=C(\\C#N)c2cc(OCCCCCCCC)c(*)cc2OC)cc1OC",
         null,
         null
        ],
        [
         "27",
         null,
         null,
         null,
         null,
         null,
         null,
         "*/C(C#N)=C/c1cc(OCCCCCCCCCC)c(/C=C(\\C#N)c2cc(OCCCCCCCCCC)c(*)cc2OC)cc1OC",
         null,
         null
        ],
        [
         "28",
         null,
         null,
         null,
         null,
         null,
         null,
         "*/C(C#N)=C/c1cc(OCCCCCCCCCCCC)c(/C=C(\\C#N)c2cc(OCCCCCCCCCCCC)c(*)cc2OC)cc1OC",
         null,
         null
        ],
        [
         "29",
         null,
         null,
         null,
         null,
         null,
         null,
         "*/C(C#N)=C/c1cc(OCCCCCCCCCCCCCCCC)c(/C=C(\\C#N)c2cc(OCCCCCCCCCCCCCCCC)c(*)cc2OC)cc1OC",
         null,
         null
        ],
        [
         "30",
         null,
         null,
         null,
         null,
         null,
         null,
         "*/C(C#N)=C/c1ccc(N(CC)Cc2ccccc2CN(CC)c2ccc(/C=C(\\C#N)S(*)(=O)=O)cc2)cc1",
         null,
         null
        ],
        [
         "31",
         null,
         null,
         null,
         null,
         null,
         null,
         "*/C(C)=C(/*)CCC",
         null,
         null
        ],
        [
         "32",
         null,
         null,
         null,
         null,
         null,
         null,
         "*/C(C)=C(/*)CCCCC",
         null,
         null
        ],
        [
         "33",
         null,
         null,
         null,
         null,
         null,
         null,
         "*/C(C)=C(/*)CCCCCCC",
         null,
         null
        ],
        [
         "34",
         null,
         null,
         null,
         null,
         null,
         null,
         "*/C(C)=C(/*)SCC",
         null,
         null
        ],
        [
         "35",
         null,
         null,
         null,
         null,
         null,
         null,
         "*/C(C)=C(/*)SCCCCCC",
         null,
         null
        ],
        [
         "36",
         null,
         null,
         null,
         null,
         null,
         null,
         "*/C(C)=C(/*)SCCCCCCCCCC",
         null,
         null
        ],
        [
         "37",
         null,
         null,
         null,
         null,
         null,
         null,
         "*/C(C)=C(/*)[Si](C)(C)C",
         null,
         null
        ],
        [
         "38",
         null,
         null,
         null,
         null,
         null,
         null,
         "*/C(C)=C(/*)[Si](C)(C)CCCCCC",
         null,
         null
        ],
        [
         "39",
         null,
         null,
         null,
         null,
         null,
         null,
         "*/C(C)=C(/*)[Si](C)(C)CC[Si](C)(C)C",
         null,
         null
        ],
        [
         "40",
         null,
         null,
         null,
         null,
         null,
         null,
         "*/C(C)=C(/*)[Si](C)(C)C[Si](C)(C)C",
         null,
         null
        ],
        [
         "41",
         null,
         null,
         null,
         null,
         null,
         null,
         "*/C(C)=C(/*)c1ccc([Si](C)(C)C)cc1",
         null,
         null
        ],
        [
         "42",
         null,
         null,
         null,
         null,
         null,
         null,
         "*/C(C)=[C](/*)[Ge]([CH3])([CH3])[CH3]",
         null,
         null
        ],
        [
         "43",
         null,
         null,
         null,
         null,
         null,
         null,
         "*/C(CC)=C(/*)c1ccccc1",
         null,
         null
        ],
        [
         "44",
         null,
         null,
         null,
         null,
         null,
         null,
         "*/C(CCCCCC)=C(/*)c1ccccc1",
         null,
         null
        ],
        [
         "45",
         null,
         null,
         null,
         null,
         null,
         null,
         "*/C(Cl)=C(/*)CCCC",
         null,
         null
        ],
        [
         "46",
         null,
         null,
         null,
         null,
         null,
         null,
         "*/C(Cl)=C(/*)CCCCCC",
         null,
         null
        ],
        [
         "47",
         null,
         null,
         null,
         null,
         null,
         null,
         "*/C(Cl)=C(/*)CCCCCCCC",
         null,
         null
        ],
        [
         "48",
         null,
         null,
         null,
         null,
         null,
         null,
         "*/C(Cl)=C(/*)c1ccccc1",
         null,
         null
        ],
        [
         "49",
         "38242048.0",
         null,
         null,
         "0.102",
         null,
         null,
         "*/C(F)=C(\\F)C(F)(C(*)(F)F)C(F)(F)F",
         null,
         "0.102"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 10343
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Tg</th>\n",
       "      <th>FFV</th>\n",
       "      <th>Tc</th>\n",
       "      <th>Density</th>\n",
       "      <th>Rg</th>\n",
       "      <th>canonical_SMILES</th>\n",
       "      <th>sanitization_error</th>\n",
       "      <th>TC_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*/C(=C(/*)c1ccc(C(C)(C)C)cc1)c1ccccc1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*/C(=C(/*)c1ccc(CCCC)cc1)c1ccccc1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*/C(=C(/*)c1ccc(Oc2ccccc2)cc1)c1ccccc1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*/C(=C(/*)c1ccc([Si](C(C)C)(C(C)C)C(C)C)cc1)c1...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*/C(=C(/*)c1ccc([Si](C)(C)C)cc1)c1ccccc1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10338</th>\n",
       "      <td>1.115536e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.38800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*c1sc(*)c(OCCCCCCCCCCCCCCCC)c1C</td>\n",
       "      <td>None</td>\n",
       "      <td>0.38800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10339</th>\n",
       "      <td>2.731393e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.37475</td>\n",
       "      <td>0.904355</td>\n",
       "      <td>14.348260</td>\n",
       "      <td>*c1sc(*)c(OCCCCCCCCCCCCCCCCCCCC)c1C</td>\n",
       "      <td>None</td>\n",
       "      <td>0.37475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10340</th>\n",
       "      <td>4.633390e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.44475</td>\n",
       "      <td>0.968872</td>\n",
       "      <td>15.087862</td>\n",
       "      <td>*c1sc(*)c2c1OCC(CCCCCCCCCCCCCCCC)O2</td>\n",
       "      <td>None</td>\n",
       "      <td>0.44475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10341</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*c1sc(*)c2sc(CCCCCCCCC)nc12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.48200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10342</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*c1sc(-c2cc(CCCCCCCCCC)c(*)s2)cc1CCCCCCCCCC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.30700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10343 rows √ó 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  Tg  FFV       Tc   Density         Rg  \\\n",
       "0               NaN NaN  NaN      NaN       NaN        NaN   \n",
       "1               NaN NaN  NaN      NaN       NaN        NaN   \n",
       "2               NaN NaN  NaN      NaN       NaN        NaN   \n",
       "3               NaN NaN  NaN      NaN       NaN        NaN   \n",
       "4               NaN NaN  NaN      NaN       NaN        NaN   \n",
       "...             ...  ..  ...      ...       ...        ...   \n",
       "10338  1.115536e+09 NaN  NaN  0.38800       NaN        NaN   \n",
       "10339  2.731393e+08 NaN  NaN  0.37475  0.904355  14.348260   \n",
       "10340  4.633390e+08 NaN  NaN  0.44475  0.968872  15.087862   \n",
       "10341           NaN NaN  NaN      NaN       NaN        NaN   \n",
       "10342           NaN NaN  NaN      NaN       NaN        NaN   \n",
       "\n",
       "                                        canonical_SMILES sanitization_error  \\\n",
       "0                  */C(=C(/*)c1ccc(C(C)(C)C)cc1)c1ccccc1                NaN   \n",
       "1                      */C(=C(/*)c1ccc(CCCC)cc1)c1ccccc1                NaN   \n",
       "2                 */C(=C(/*)c1ccc(Oc2ccccc2)cc1)c1ccccc1                NaN   \n",
       "3      */C(=C(/*)c1ccc([Si](C(C)C)(C(C)C)C(C)C)cc1)c1...                NaN   \n",
       "4               */C(=C(/*)c1ccc([Si](C)(C)C)cc1)c1ccccc1                NaN   \n",
       "...                                                  ...                ...   \n",
       "10338                    *c1sc(*)c(OCCCCCCCCCCCCCCCC)c1C               None   \n",
       "10339                *c1sc(*)c(OCCCCCCCCCCCCCCCCCCCC)c1C               None   \n",
       "10340                *c1sc(*)c2c1OCC(CCCCCCCCCCCCCCCC)O2               None   \n",
       "10341                        *c1sc(*)c2sc(CCCCCCCCC)nc12                NaN   \n",
       "10342        *c1sc(-c2cc(CCCCCCCCCC)c(*)s2)cc1CCCCCCCCCC                NaN   \n",
       "\n",
       "       TC_mean  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4          NaN  \n",
       "...        ...  \n",
       "10338  0.38800  \n",
       "10339  0.37475  \n",
       "10340  0.44475  \n",
       "10341  0.48200  \n",
       "10342  0.30700  \n",
       "\n",
       "[10343 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "047a4944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Tg",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "FFV",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Tc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Density",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Rg",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "canonical_SMILES",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "TC_mean",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "ad19daff-6db9-4251-b4a8-fb9ec6f07a94",
       "rows": [
        [
         "0",
         null,
         null,
         null,
         null,
         null,
         "*/C(=C(/*)c1ccc(C(C)(C)C)cc1)c1ccccc1",
         null
        ],
        [
         "1",
         null,
         null,
         null,
         null,
         null,
         "*/C(=C(/*)c1ccc(CCCC)cc1)c1ccccc1",
         null
        ],
        [
         "2",
         null,
         null,
         null,
         null,
         null,
         "*/C(=C(/*)c1ccc(Oc2ccccc2)cc1)c1ccccc1",
         null
        ],
        [
         "3",
         null,
         null,
         null,
         null,
         null,
         "*/C(=C(/*)c1ccc([Si](C(C)C)(C(C)C)C(C)C)cc1)c1ccccc1",
         null
        ],
        [
         "4",
         null,
         null,
         null,
         null,
         null,
         "*/C(=C(/*)c1ccc([Si](C)(C)C)cc1)c1ccccc1",
         null
        ],
        [
         "5",
         null,
         null,
         null,
         null,
         null,
         "*/C(=C(/*)c1ccc[c]([Ge]([CH3])([CH3])[CH3])c1)c1ccccc1",
         null
        ],
        [
         "6",
         null,
         null,
         null,
         null,
         null,
         "*/C(=C(/*)c1cccc([Si](C)(C)C)c1)c1ccccc1",
         null
        ],
        [
         "7",
         "206.5698859",
         null,
         null,
         null,
         null,
         "*/C(=C(/*)c1ccccc1)c1ccccc1",
         null
        ],
        [
         "8",
         null,
         null,
         null,
         null,
         null,
         "*/C(=C(/c1ccc(*)cc1)c1ccc(Oc2ccccc2)cc1)c1ccc(Oc2ccccc2)cc1",
         null
        ],
        [
         "9",
         null,
         null,
         null,
         null,
         null,
         "*/C(=C(\\C#N)c1ccc(C(=O)OC2CCN(*)CC2)cc1)c1ccc(OC)cc1",
         null
        ],
        [
         "10",
         null,
         null,
         null,
         null,
         null,
         "*/C(=C(\\[2H])C([2H])([2H])C(*)([2H])[2H])C([2H])([2H])[2H]",
         null
        ],
        [
         "11",
         null,
         null,
         null,
         null,
         null,
         "*/C(=C(\\c1ccccc1)c1ccc(*)cc1)c1ccccc1",
         "0.338"
        ],
        [
         "12",
         null,
         null,
         null,
         null,
         null,
         "*/C(=C/c1cc(OC)c(/C=C(/c2ccc(*)cc2)c2ccc(C(F)(F)F)cc2)cc1OC)c1ccc(C(F)(F)F)cc1",
         null
        ],
        [
         "13",
         null,
         null,
         null,
         null,
         null,
         "*/C(=C/c1cc(OC)c(/C=C(/c2ccc(*)cc2)c2ccc(F)cc2)cc1OC)c1ccc(F)cc1",
         null
        ],
        [
         "14",
         null,
         null,
         null,
         null,
         null,
         "*/C(=C/c1cc(OC)c(/C=C(/c2ccc(*)cc2)c2ccc(OC)cc2)cc1OC)c1ccc(OC)cc1",
         null
        ],
        [
         "15",
         null,
         null,
         null,
         null,
         null,
         "*/C(=C/c1cc(OC)c(/C=C(\\c2ccc(F)cc2)c2ccc(-c3ccc(*)cc3)cc2)cc1OC)c1ccc(F)cc1",
         null
        ],
        [
         "16",
         null,
         null,
         null,
         null,
         null,
         "*/C(=C/c1cc(OC)c(/C=C(\\c2ccc(F)cc2)c2ccc3cc(*)ccc3c2)cc1OC)c1ccc(F)cc1",
         null
        ],
        [
         "17",
         null,
         null,
         null,
         null,
         null,
         "*/C(=C/c1cc(OC)c(/C=C(\\c2ccccc2)c2ccc(-c3ccc(*)cc3)cc2)cc1OC)c1ccccc1",
         null
        ],
        [
         "18",
         null,
         null,
         null,
         null,
         null,
         "*/C(=C/c1cc(OC)c(/C=C(\\c2ccccc2)c2ccc3cc(*)ccc3c2)cc1OC)c1ccccc1",
         null
        ],
        [
         "19",
         null,
         null,
         null,
         null,
         null,
         "*/C(=C/c1cc(OCCCCCCCC)c(/C=C(\\c2ccccc2)c2ccc3c(c2)Sc2ccc(*)cc2S3)cc1OCCCCCCCC)c1ccccc1",
         null
        ],
        [
         "20",
         null,
         null,
         null,
         null,
         null,
         "*/C(=C/c1ccc(/C=C(\\c2ccccc2)c2ccc(-c3ccc(*)cc3)cc2)cc1)c1ccccc1",
         null
        ],
        [
         "21",
         null,
         null,
         null,
         null,
         null,
         "*/C(=N\\c1ccccc1)c1ccc(-c2ccc(*)cc2)cc1",
         null
        ],
        [
         "22",
         null,
         null,
         null,
         null,
         null,
         "*/C(C#N)=C(\\C#N)N1C(=O)c2ccc(C(=O)c3ccc(-c4ccc5c(c4)C(=O)N(*)C5=O)cc3)cc2C1=O",
         null
        ],
        [
         "23",
         null,
         null,
         null,
         null,
         null,
         "*/C(C#N)=C(\\C#N)n1c(=O)c2cc3c(=O)n(*)c(=O)c3cc2c1=O",
         null
        ],
        [
         "24",
         null,
         null,
         null,
         null,
         null,
         "*/C(C#N)=C/c1cc(/C=C(\\C#N)c2ccc3c(c2)C(CCCCCCCC)(CCCCCCCC)c2cc(*)ccc2-3)cc(N(c2ccccc2)c2ccccc2)c1",
         null
        ],
        [
         "25",
         null,
         null,
         null,
         null,
         null,
         "*/C(C#N)=C/c1cc(OCC(CC)CCCC)c(/C=C(\\C#N)c2ccc3c4ccc(*)cc4n(CC(CC)CCCC)c3c2)cc1OCC(CC)CCCC",
         null
        ],
        [
         "26",
         null,
         null,
         null,
         null,
         null,
         "*/C(C#N)=C/c1cc(OCCCCCCCC)c(/C=C(\\C#N)c2cc(OCCCCCCCC)c(*)cc2OC)cc1OC",
         null
        ],
        [
         "27",
         null,
         null,
         null,
         null,
         null,
         "*/C(C#N)=C/c1cc(OCCCCCCCCCC)c(/C=C(\\C#N)c2cc(OCCCCCCCCCC)c(*)cc2OC)cc1OC",
         null
        ],
        [
         "28",
         null,
         null,
         null,
         null,
         null,
         "*/C(C#N)=C/c1cc(OCCCCCCCCCCCC)c(/C=C(\\C#N)c2cc(OCCCCCCCCCCCC)c(*)cc2OC)cc1OC",
         null
        ],
        [
         "29",
         null,
         null,
         null,
         null,
         null,
         "*/C(C#N)=C/c1cc(OCCCCCCCCCCCCCCCC)c(/C=C(\\C#N)c2cc(OCCCCCCCCCCCCCCCC)c(*)cc2OC)cc1OC",
         null
        ],
        [
         "30",
         null,
         null,
         null,
         null,
         null,
         "*/C(C#N)=C/c1ccc(N(CC)Cc2ccccc2CN(CC)c2ccc(/C=C(\\C#N)S(*)(=O)=O)cc2)cc1",
         null
        ],
        [
         "31",
         null,
         null,
         null,
         null,
         null,
         "*/C(C)=C(/*)CCC",
         null
        ],
        [
         "32",
         null,
         null,
         null,
         null,
         null,
         "*/C(C)=C(/*)CCCCC",
         null
        ],
        [
         "33",
         null,
         null,
         null,
         null,
         null,
         "*/C(C)=C(/*)CCCCCCC",
         null
        ],
        [
         "34",
         null,
         null,
         null,
         null,
         null,
         "*/C(C)=C(/*)SCC",
         null
        ],
        [
         "35",
         null,
         null,
         null,
         null,
         null,
         "*/C(C)=C(/*)SCCCCCC",
         null
        ],
        [
         "36",
         null,
         null,
         null,
         null,
         null,
         "*/C(C)=C(/*)SCCCCCCCCCC",
         null
        ],
        [
         "37",
         null,
         null,
         null,
         null,
         null,
         "*/C(C)=C(/*)[Si](C)(C)C",
         null
        ],
        [
         "38",
         null,
         null,
         null,
         null,
         null,
         "*/C(C)=C(/*)[Si](C)(C)CCCCCC",
         null
        ],
        [
         "39",
         null,
         null,
         null,
         null,
         null,
         "*/C(C)=C(/*)[Si](C)(C)CC[Si](C)(C)C",
         null
        ],
        [
         "40",
         null,
         null,
         null,
         null,
         null,
         "*/C(C)=C(/*)[Si](C)(C)C[Si](C)(C)C",
         null
        ],
        [
         "41",
         null,
         null,
         null,
         null,
         null,
         "*/C(C)=C(/*)c1ccc([Si](C)(C)C)cc1",
         null
        ],
        [
         "42",
         null,
         null,
         null,
         null,
         null,
         "*/C(C)=[C](/*)[Ge]([CH3])([CH3])[CH3]",
         null
        ],
        [
         "43",
         null,
         null,
         null,
         null,
         null,
         "*/C(CC)=C(/*)c1ccccc1",
         null
        ],
        [
         "44",
         null,
         null,
         null,
         null,
         null,
         "*/C(CCCCCC)=C(/*)c1ccccc1",
         null
        ],
        [
         "45",
         null,
         null,
         null,
         null,
         null,
         "*/C(Cl)=C(/*)CCCC",
         null
        ],
        [
         "46",
         null,
         null,
         null,
         null,
         null,
         "*/C(Cl)=C(/*)CCCCCC",
         null
        ],
        [
         "47",
         null,
         null,
         null,
         null,
         null,
         "*/C(Cl)=C(/*)CCCCCCCC",
         null
        ],
        [
         "48",
         null,
         null,
         null,
         null,
         null,
         "*/C(Cl)=C(/*)c1ccccc1",
         null
        ],
        [
         "49",
         null,
         null,
         "0.102",
         null,
         null,
         "*/C(F)=C(\\F)C(F)(C(*)(F)F)C(F)(F)F",
         "0.102"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 10343
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tg</th>\n",
       "      <th>FFV</th>\n",
       "      <th>Tc</th>\n",
       "      <th>Density</th>\n",
       "      <th>Rg</th>\n",
       "      <th>canonical_SMILES</th>\n",
       "      <th>TC_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*/C(=C(/*)c1ccc(C(C)(C)C)cc1)c1ccccc1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*/C(=C(/*)c1ccc(CCCC)cc1)c1ccccc1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*/C(=C(/*)c1ccc(Oc2ccccc2)cc1)c1ccccc1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*/C(=C(/*)c1ccc([Si](C(C)C)(C(C)C)C(C)C)cc1)c1...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*/C(=C(/*)c1ccc([Si](C)(C)C)cc1)c1ccccc1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10338</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.38800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*c1sc(*)c(OCCCCCCCCCCCCCCCC)c1C</td>\n",
       "      <td>0.38800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10339</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.37475</td>\n",
       "      <td>0.904355</td>\n",
       "      <td>14.348260</td>\n",
       "      <td>*c1sc(*)c(OCCCCCCCCCCCCCCCCCCCC)c1C</td>\n",
       "      <td>0.37475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10340</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.44475</td>\n",
       "      <td>0.968872</td>\n",
       "      <td>15.087862</td>\n",
       "      <td>*c1sc(*)c2c1OCC(CCCCCCCCCCCCCCCC)O2</td>\n",
       "      <td>0.44475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10341</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*c1sc(*)c2sc(CCCCCCCCC)nc12</td>\n",
       "      <td>0.48200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10342</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*c1sc(-c2cc(CCCCCCCCCC)c(*)s2)cc1CCCCCCCCCC</td>\n",
       "      <td>0.30700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10343 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Tg  FFV       Tc   Density         Rg  \\\n",
       "0     NaN  NaN      NaN       NaN        NaN   \n",
       "1     NaN  NaN      NaN       NaN        NaN   \n",
       "2     NaN  NaN      NaN       NaN        NaN   \n",
       "3     NaN  NaN      NaN       NaN        NaN   \n",
       "4     NaN  NaN      NaN       NaN        NaN   \n",
       "...    ..  ...      ...       ...        ...   \n",
       "10338 NaN  NaN  0.38800       NaN        NaN   \n",
       "10339 NaN  NaN  0.37475  0.904355  14.348260   \n",
       "10340 NaN  NaN  0.44475  0.968872  15.087862   \n",
       "10341 NaN  NaN      NaN       NaN        NaN   \n",
       "10342 NaN  NaN      NaN       NaN        NaN   \n",
       "\n",
       "                                        canonical_SMILES  TC_mean  \n",
       "0                  */C(=C(/*)c1ccc(C(C)(C)C)cc1)c1ccccc1      NaN  \n",
       "1                      */C(=C(/*)c1ccc(CCCC)cc1)c1ccccc1      NaN  \n",
       "2                 */C(=C(/*)c1ccc(Oc2ccccc2)cc1)c1ccccc1      NaN  \n",
       "3      */C(=C(/*)c1ccc([Si](C(C)C)(C(C)C)C(C)C)cc1)c1...      NaN  \n",
       "4               */C(=C(/*)c1ccc([Si](C)(C)C)cc1)c1ccccc1      NaN  \n",
       "...                                                  ...      ...  \n",
       "10338                    *c1sc(*)c(OCCCCCCCCCCCCCCCC)c1C  0.38800  \n",
       "10339                *c1sc(*)c(OCCCCCCCCCCCCCCCCCCCC)c1C  0.37475  \n",
       "10340                *c1sc(*)c2c1OCC(CCCCCCCCCCCCCCCC)O2  0.44475  \n",
       "10341                        *c1sc(*)c2sc(CCCCCCCCC)nc12  0.48200  \n",
       "10342        *c1sc(-c2cc(CCCCCCCCCC)c(*)s2)cc1CCCCCCCCCC  0.30700  \n",
       "\n",
       "[10343 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_augmented = df_augmented.drop(columns=[\"sanitization_error\",\"id\"])\n",
    "df_augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dcc58178",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "save_dir = \"../data\"  # relative dari src/\n",
    "save_path = os.path.join(save_dir, \"augmented_training_data.csv\")\n",
    "\n",
    "df_augmented.to_csv(save_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c5ae609",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\dl_env\\lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import numpy as np\n",
    "\n",
    "def get_atom_features(atom):\n",
    "    \"\"\"\n",
    "    Extract node features from RDKit atom object.\n",
    "    Features: atomic number, valence, degree, formal charge, aromaticity\n",
    "    \"\"\"\n",
    "    features = [\n",
    "        atom.GetAtomicNum(),                    # Atomic number\n",
    "        atom.GetTotalValence(),                 # Valence\n",
    "        atom.GetDegree(),                       # Degree\n",
    "        atom.GetFormalCharge(),                 # Formal charge\n",
    "        int(atom.GetIsAromatic())               # Aromaticity (0 or 1)\n",
    "    ]\n",
    "    return features\n",
    "\n",
    "def get_bond_features(bond):\n",
    "    \"\"\"\n",
    "    Extract edge features from RDKit bond object.\n",
    "    Features: bond type, conjugation, aromatic flags\n",
    "    \"\"\"\n",
    "    bond_type_map = {\n",
    "        Chem.BondType.SINGLE: 1,\n",
    "        Chem.BondType.DOUBLE: 2,\n",
    "        Chem.BondType.TRIPLE: 3,\n",
    "        Chem.BondType.AROMATIC: 4\n",
    "    }\n",
    "    \n",
    "    features = [\n",
    "        bond_type_map.get(bond.GetBondType(), 0),  # Bond type\n",
    "        int(bond.GetIsConjugated()),                # Conjugation\n",
    "        int(bond.GetIsAromatic())                   # Aromatic flag\n",
    "    ]\n",
    "    return features\n",
    "\n",
    "def smiles_to_graph(smiles):\n",
    "    \"\"\"\n",
    "    Convert SMILES string to PyTorch Geometric Data object.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    Data object with:\n",
    "        - x: node feature matrix [num_nodes, 5]\n",
    "        - edge_index: edge connectivity [2, num_edges]\n",
    "        - edge_attr: edge features [num_edges, 3]\n",
    "    \"\"\"\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    \n",
    "    # Node features\n",
    "    atom_features = []\n",
    "    for atom in mol.GetAtoms():\n",
    "        atom_features.append(get_atom_features(atom))\n",
    "    x = torch.tensor(atom_features, dtype=torch.float)\n",
    "    \n",
    "    # Edge indices and features\n",
    "    edge_indices = []\n",
    "    edge_features = []\n",
    "    \n",
    "    for bond in mol.GetBonds():\n",
    "        i = bond.GetBeginAtomIdx()\n",
    "        j = bond.GetEndAtomIdx()\n",
    "        \n",
    "        # Add both directions (undirected graph)\n",
    "        edge_indices.append([i, j])\n",
    "        edge_indices.append([j, i])\n",
    "        \n",
    "        bond_feat = get_bond_features(bond)\n",
    "        edge_features.append(bond_feat)\n",
    "        edge_features.append(bond_feat)\n",
    "    \n",
    "    edge_index = torch.tensor(edge_indices, dtype=torch.long).t().contiguous()\n",
    "    edge_attr = torch.tensor(edge_features, dtype=torch.float)\n",
    "    \n",
    "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "53c70213",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Dataset, DataLoader, Batch\n",
    "import pandas as pd\n",
    "\n",
    "class PolymerDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom dataset for polymer property prediction.\n",
    "    \"\"\"\n",
    "    def __init__(self, df, target_columns=['Tg', 'FFV', 'Tc', 'Density', 'Rg']):\n",
    "        super().__init__()\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.target_columns = target_columns\n",
    "        self.smiles_column = 'canonical_SMILES'\n",
    "        \n",
    "        # Filter out rows with all NaN targets\n",
    "        valid_rows = self.df[target_columns].notna().any(axis=1)\n",
    "        self.df = self.df[valid_rows].reset_index(drop=True)\n",
    "        \n",
    "    def len(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def get(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        smiles = row[self.smiles_column]\n",
    "        \n",
    "        # Convert SMILES to graph\n",
    "        graph = smiles_to_graph(smiles)\n",
    "        if graph is None:\n",
    "            return None\n",
    "        \n",
    "        # Extract target values (handle NaN)\n",
    "        targets = []\n",
    "        target_mask = []\n",
    "        for col in self.target_columns:\n",
    "            val = row[col]\n",
    "            if pd.isna(val):\n",
    "                targets.append(0.0)\n",
    "                target_mask.append(0)\n",
    "            else:\n",
    "                targets.append(float(val))\n",
    "                target_mask.append(1)\n",
    "        \n",
    "        graph.y = torch.tensor([targets], dtype=torch.float)  # ‚Üê FIX: Add extra dimension\n",
    "        graph.y_mask = torch.tensor([target_mask], dtype=torch.float)  # ‚Üê FIX: Add extra dimension\n",
    "        \n",
    "        return graph\n",
    "\n",
    "def custom_collate(batch):\n",
    "    \"\"\"\n",
    "    Custom collate function to handle None values and properly batch graphs.\n",
    "    \"\"\"\n",
    "    # Filter out None values\n",
    "    batch = [item for item in batch if item is not None]\n",
    "    \n",
    "    if len(batch) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Use PyTorch Geometric's Batch.from_data_list\n",
    "    return Batch.from_data_list(batch)\n",
    "\n",
    "def create_dataloaders(df, batch_size=32, train_split=0.8):\n",
    "    \"\"\"\n",
    "    Create train and validation dataloaders.\n",
    "    \"\"\"\n",
    "    dataset = PolymerDataset(df)\n",
    "    \n",
    "    # Train/val split\n",
    "    train_size = int(train_split * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    \n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "        dataset, [train_size, val_size]\n",
    "    )\n",
    "    \n",
    "    # Use custom collate function\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True,\n",
    "        collate_fn=custom_collate  # ‚Üê ADD THIS\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False,\n",
    "        collate_fn=custom_collate  # ‚Üê ADD THIS\n",
    "    )\n",
    "    \n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b0a22cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GraphConv, global_mean_pool\n",
    "\n",
    "class PolymerGNN(nn.Module):\n",
    "    \"\"\"\n",
    "    3-layer Graph Convolutional Network for polymer property prediction.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_node_features=5, num_outputs=5, hidden_dim=64, embedding_dim=32):\n",
    "        super(PolymerGNN, self).__init__()\n",
    "        \n",
    "        # Graph convolution layers\n",
    "        self.conv1 = GraphConv(num_node_features, hidden_dim)\n",
    "        self.conv2 = GraphConv(hidden_dim, hidden_dim)\n",
    "        self.conv3 = GraphConv(hidden_dim, embedding_dim)\n",
    "        \n",
    "        # Batch normalization\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.bn3 = nn.BatchNorm1d(embedding_dim)\n",
    "        \n",
    "        # Dense layers for property prediction\n",
    "        self.fc1 = nn.Linear(embedding_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, num_outputs)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        \n",
    "        # GCN layers with ReLU and batch norm\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = self.bn3(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # Global mean pooling (32-dim embeddings)\n",
    "        embeddings = global_mean_pool(x, batch)\n",
    "        \n",
    "        # Dense layers for final predictions\n",
    "        x = F.relu(self.fc1(embeddings))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def get_embeddings(self, data):\n",
    "        \"\"\"Extract 32-dim molecular embeddings.\"\"\"\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        \n",
    "        x = F.relu(self.bn1(self.conv1(x, edge_index)))\n",
    "        x = F.relu(self.bn2(self.conv2(x, edge_index)))\n",
    "        x = F.relu(self.bn3(self.conv3(x, edge_index)))\n",
    "        \n",
    "        return global_mean_pool(x, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "46a1c62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embeddings_for_xgboost(model, dataloader, device):\n",
    "    \"\"\"\n",
    "    Extract 32D embeddings from GNN for all molecules.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    targets = []\n",
    "    masks = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            if batch is None:\n",
    "                continue\n",
    "            batch = batch.to(device)\n",
    "            \n",
    "            # Use get_embeddings() method\n",
    "            emb = model.get_embeddings(batch)  # Shape: [batch_size, 32]\n",
    "            \n",
    "            embeddings.append(emb.cpu().numpy())\n",
    "            targets.append(batch.y.cpu().numpy())\n",
    "            masks.append(batch.y_mask.cpu().numpy())\n",
    "    \n",
    "    embeddings = np.vstack(embeddings)  # [num_samples, 32]\n",
    "    targets = np.vstack(targets)        # [num_samples, 5]\n",
    "    masks = np.vstack(masks)            # [num_samples, 5]\n",
    "    \n",
    "    return embeddings, targets, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a110dad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Masked MSE Loss\n",
    "# ---------------------------------------------------------\n",
    "def masked_mse_loss(pred, target, mask):\n",
    "    \"\"\"\n",
    "    Compute MSE only over available target values.\n",
    "    pred, target, mask = [batch, 5]\n",
    "    \"\"\"\n",
    "    # Sanity reshape if dataloader flattens targets\n",
    "    if target.dim() == 1:\n",
    "        target = target.view(pred.shape[0], -1)\n",
    "        mask   = mask.view(pred.shape[0], -1)\n",
    "\n",
    "    loss = (pred - target) ** 2\n",
    "    loss = loss * mask\n",
    "    return loss.sum() / mask.sum().clamp(min=1)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Training loop for one epoch\n",
    "# ---------------------------------------------------------\n",
    "def train_epoch(model, loader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for batch in tqdm(loader, desc=\"Training\"):\n",
    "        if batch is None:\n",
    "            continue\n",
    "\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(batch)\n",
    "        loss = masked_mse_loss(pred, batch.y, batch.y_mask)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / max(len(loader), 1)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Validation loop\n",
    "# ---------------------------------------------------------\n",
    "def validate(model, loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            if batch is None:\n",
    "                continue\n",
    "\n",
    "            batch = batch.to(device)\n",
    "            pred = model(batch)\n",
    "            loss = masked_mse_loss(pred, batch.y, batch.y_mask)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss / max(len(loader), 1)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Full Training Procedure\n",
    "# ---------------------------------------------------------\n",
    "def train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    num_epochs=100,\n",
    "    lr=1e-3,\n",
    "    device=None\n",
    "):\n",
    "    # Resolve device\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    print(f\"\\nüöÄ Using device: {device}\")\n",
    "\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        patience=10,\n",
    "        factor=0.5\n",
    "    )\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, device)\n",
    "        val_loss   = validate(model, val_loader, device)\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        print(f\"\\nEpoch {epoch}/{num_epochs}\")\n",
    "        print(f\"Train Loss: {train_loss:.6f} | Val Loss: {val_loss:.6f}\")\n",
    "\n",
    "        # Save best\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), \"best_model.pt\")\n",
    "            print(\"üíæ Saved new best model!\")\n",
    "\n",
    "    print(\"\\nüéâ Training complete! Best Val Loss:\", best_val_loss)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ee9e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Loq Gaming\\AppData\\Local\\Temp\\ipykernel_29408\\7337724.py:76: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  train_loader = DataLoader(\n",
      "C:\\Users\\Loq Gaming\\AppData\\Local\\Temp\\ipykernel_29408\\7337724.py:82: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  val_loader = DataLoader(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:07<00:00, 26.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/50\n",
      "Train Loss: 1071.019105 | Val Loss: 993.503101\n",
      "üíæ Saved new best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:06<00:00, 29.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/50\n",
      "Train Loss: 663.650427 | Val Loss: 441.504191\n",
      "üíæ Saved new best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:06<00:00, 30.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/50\n",
      "Train Loss: 404.355163 | Val Loss: 317.145170\n",
      "üíæ Saved new best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:06<00:00, 30.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/50\n",
      "Train Loss: 347.468621 | Val Loss: 330.896447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:06<00:00, 28.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/50\n",
      "Train Loss: 343.920606 | Val Loss: 303.536935\n",
      "üíæ Saved new best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:07<00:00, 26.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/50\n",
      "Train Loss: 329.900796 | Val Loss: 287.730844\n",
      "üíæ Saved new best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:06<00:00, 28.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7/50\n",
      "Train Loss: 325.089214 | Val Loss: 283.863946\n",
      "üíæ Saved new best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:06<00:00, 31.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8/50\n",
      "Train Loss: 306.252276 | Val Loss: 289.286998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:06<00:00, 31.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9/50\n",
      "Train Loss: 289.452673 | Val Loss: 317.312888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:06<00:00, 30.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/50\n",
      "Train Loss: 305.005195 | Val Loss: 294.690692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:06<00:00, 29.78it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Step 1: Train GNN to learn embeddings\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = PolymerGNN(num_node_features=5, num_outputs=5).to(device)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader, val_loader = create_dataloaders(df_augmented, batch_size=32, train_split=0.8)\n",
    "\n",
    "# Train GNN\n",
    "train_model(model, train_loader, val_loader, num_epochs=50, device=device)\n",
    "\n",
    "# Step 2: Extract embeddings\n",
    "print(\"\\nüîÑ Extracting embeddings for XGBoost...\")\n",
    "train_emb, train_y, train_mask = extract_embeddings_for_xgboost(model, train_loader, device)\n",
    "val_emb, val_y, val_mask = extract_embeddings_for_xgboost(model, val_loader, device)\n",
    "\n",
    "print(f\"Train embeddings shape: {train_emb.shape}\")  # Should be [N_train, 32]\n",
    "print(f\"Val embeddings shape: {val_emb.shape}\")      # Should be [N_val, 32]\n",
    "\n",
    "# Step 3: Train XGBoost on embeddings\n",
    "print(\"\\nüå≥ Training XGBoost on GNN embeddings...\")\n",
    "\n",
    "# Define XGBoost base regressor\n",
    "base_xgb = XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Multi-output wrapper\n",
    "xgb_model = MultiOutputRegressor(base_xgb)\n",
    "\n",
    "# Train on embeddings\n",
    "xgb_model.fit(train_emb, train_y)\n",
    "\n",
    "# Step 4: Evaluate\n",
    "val_pred = xgb_model.predict(val_emb)\n",
    "\n",
    "# Calculate metrics per property\n",
    "property_names = ['Tg', 'FFV', 'Tc', 'Density', 'Rg']\n",
    "print(\"\\nüìä XGBoost Performance:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, prop in enumerate(property_names):\n",
    "    # Only evaluate where target is available\n",
    "    mask_idx = val_mask[:, i] == 1\n",
    "    \n",
    "    if mask_idx.sum() > 0:\n",
    "        y_true = val_y[mask_idx, i]\n",
    "        y_pred = val_pred[mask_idx, i]\n",
    "        \n",
    "        mse = mean_squared_error(y_true, y_pred)\n",
    "        r2 = r2_score(y_true, y_pred)\n",
    "        \n",
    "        print(f\"{prop:10s} | MSE: {mse:.4f} | R¬≤: {r2:.4f} | N: {mask_idx.sum()}\")\n",
    "    else:\n",
    "        print(f\"{prop:10s} | No validation samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f183137d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deep Learning Env",
   "language": "python",
   "name": "dl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
